{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "\n",
    "from web_crawler import grabDomainRoot\n",
    "\n",
    "'''\n",
    "randomWalk(graph, initial_node, step, max_step, path)\n",
    "\n",
    "Function to take a random walk from a given node\n",
    "\n",
    "graph: networkx graph, graph from which to random through\n",
    "initial node: string, initial node to begin the walk\n",
    "step: int, current step of walk\n",
    "max_step: int, maximum number of steps to take in walk\n",
    "path:, list, current path taken in the walk\n",
    "'''\n",
    "def randomWalk(graph, initial_node, step, max_step, path):\n",
    " \n",
    "    if step>= max_step: \n",
    "        return path\n",
    "    \n",
    "    adjacent_nodes = [i for i in graph.neighbors(initial_node)]\n",
    "    \n",
    "    if len(adjacent_nodes) == 0:\n",
    "            path.append(None)\n",
    "            return path\n",
    "            \n",
    "    next_node = random.sample(adjacent_nodes, 1)[0]\n",
    "    \n",
    "    path.append(next_node)\n",
    "    \n",
    "    return randomWalk(graph, next_node, step+1, max_step, path)\n",
    "\n",
    "'''\n",
    "generateBatch(batch_size, num_context_per_label, context_window, target, step)\n",
    "\n",
    "batch_size: int, batch size for training\n",
    "num_context_per_label: int, how many context examples to use per label (the label is the target) \n",
    "can't be greater than the context window size\n",
    "context_window: int, size of the context window \n",
    "target: array, the list of targets for each context window\n",
    "step: int, counter for how many times to step through the same context and target data\n",
    "\n",
    "Generate the batch data for training. For each \"context window\", randomly sample a\n",
    "set of context elements and configure them as training data by constructing column data of,\n",
    "\n",
    "[target_0, context_0]\n",
    "[target_0, context_1]\n",
    "[target_0, context_3]\n",
    "...\n",
    "[target_n, context_3]\n",
    "[target_n, context_2]\n",
    "[target_n, context_1]\n",
    "\n",
    "'''\n",
    "def generateBatch(batch_size, num_context_per_label, context_window, target, step):\n",
    "\n",
    "    batch = []\n",
    "    passes_through_batch = batch_size//num_context_per_label\n",
    "    for window_idx in range(passes_through_batch):\n",
    "        \n",
    "        current_window = list(context_window[window_idx + passes_through_batch*step])\n",
    "        current_target = target[window_idx + passes_through_batch*step]\n",
    "        context_samples = -1\n",
    "        while context_samples == -1:\n",
    "            \n",
    "            context_samples = random.sample(current_window, num_context_per_label)\n",
    "        \n",
    "        data_samples =  [[context_sample, [current_target]] for context_sample in context_samples]\n",
    "\n",
    "        for data_sample in data_samples:\n",
    "            batch.append(data_sample)\n",
    "            \n",
    "    return batch\n",
    "\n",
    "black_list = ['@', ':/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file = pickle.load(open('crawler_results/graph_calls_620000_stack_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n",
      "NO BASE URL\n"
     ]
    }
   ],
   "source": [
    "#Create a graph out of the connections\n",
    "nodes_only = []\n",
    "web_graph = nx.DiGraph()\n",
    "#web_graph = nx.Graph()\n",
    "for node in graph_file.keys():\n",
    "    domain_node = grabDomainRoot(node)\n",
    "    domain_node = domain_node.lower()\n",
    "    #if domain_node == 'offers.usatoday.com':\n",
    "    #    break\n",
    "    #    print (domain_node)\n",
    "    for idx in range(0, len(graph_file[node]), 3):\n",
    "        key = graph_file[node][idx]\n",
    "\n",
    "        domain_key = grabDomainRoot(key)\n",
    "\n",
    "        if domain_node == domain_key: \n",
    "            continue        \n",
    "        \n",
    "        if domain_node is None or domain_key is None: \n",
    "            continue\n",
    "        \n",
    "        if True in [i in domain_node for i in black_list] or True in [i in domain_key for i in black_list]:\n",
    "            continue\n",
    "            \n",
    "        domain_key = domain_key.lower()\n",
    "\n",
    "        web_graph.add_edge(domain_node, domain_key)\n",
    "        nodes_only.append(domain_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_nodes = [i for i in web_graph.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_inv_map = {idx:i for idx, i in enumerate(list_of_nodes)}\n",
    "domain_map = {i:idx for idx, i in enumerate(list_of_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7347"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(no_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_next_neighbors = []\n",
    "no_neighbors = []\n",
    "for node in list_of_nodes:\n",
    "    neighbors = [i for i in web_graph.neighbors(node)]\n",
    "    for neighbor in neighbors:\n",
    "        next_neighbors = [i for i in web_graph.neighbors(neighbor)]\n",
    "    next_neighbor_counts = [len(i) for i in next_neighbors]\n",
    "    \n",
    "    if sum(next_neighbor_counts)==0:\n",
    "        no_next_neighbors.append(node)\n",
    "        \n",
    "    if len(neighbors)==0:\n",
    "        no_neighbors.append(node)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_only = list(set(nodes_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(web_graph, node_size=25)#, with_labels=True)\n",
    "plt.savefig('nytimes_root_graph_directed.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8921 nodes, 8921 key_domain dict, 1085 key_nodes only\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "#print('%d nodes, %d dict terms, %d key_domain dict' % (len(list_of_nodes), len(vocab_dict), len(key_domain_dict)))\n",
    "print('%d nodes, %d key_domain dict, %d key_nodes only' % (len(list_of_nodes), len(domain_inv_map), len(nodes_only)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 2# Window size and max_step must be connected\n",
    "\n",
    "num_skips = 1 #The number of context examples per label to create x-y data out of \n",
    "#i.e. the number of rows of \"data\" per window, label combo\n",
    "window_size = max_step//2 #where max step must be even\n",
    "embedding_size = 32  #Dimension of the embedding vector.\n",
    "vocabulary_size = len(web_graph.nodes())\n",
    "#vocabulary_size = len(nodes_only)\n",
    "\n",
    "num_sampled = 64 #Number of negative examples to sample. \n",
    "#As this number goes to the total number of samples it reproduces softmax, \n",
    "#this not quite correct as we still doing binary classification, except now we give every negative example to test against,\n",
    "#as opposed to true multi-class classification\n",
    "batch_size = 64 #must be a multiple of num_skips\n",
    "num_steps = len(nodes_only)//batch_size\n",
    "n_epochs = 10000 #This controls the number of walks from each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8921 nodes, 16 steps per epoch\n"
     ]
    }
   ],
   "source": [
    "print ('%d nodes, %d steps per epoch' % (vocabulary_size, num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "    # Look up embeddings for inputs.\n",
    "    embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "    # Construct the variables for the NCE loss\n",
    "    nce_weights = tf.Variable(\n",
    "        tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    loss = tf.reduce_mean(\n",
    "      tf.nn.nce_loss(weights=nce_weights,\n",
    "                     biases=nce_biases,\n",
    "                     labels=train_labels,\n",
    "                     inputs=embed,\n",
    "                     num_sampled=num_sampled,\n",
    "                     num_classes=vocabulary_size))\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:0, Average loss:215.4529\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:1, Average loss:211.4409\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:2, Average loss:209.9032\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:3, Average loss:209.7022\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:4, Average loss:201.3721\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:5, Average loss:196.7859\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:6, Average loss:190.6124\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:7, Average loss:194.5653\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:8, Average loss:191.3692\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:9, Average loss:188.5855\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:10, Average loss:182.9796\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:11, Average loss:185.6613\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:12, Average loss:177.9191\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:13, Average loss:177.3753\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:14, Average loss:180.5906\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:15, Average loss:180.3549\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:16, Average loss:171.3146\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:17, Average loss:172.6221\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:18, Average loss:176.1735\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:19, Average loss:167.7894\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:20, Average loss:169.8258\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:21, Average loss:168.0692\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:22, Average loss:163.5624\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:23, Average loss:173.0536\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:24, Average loss:164.152\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:25, Average loss:159.8258\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:26, Average loss:159.2785\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:27, Average loss:167.1102\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:28, Average loss:166.8415\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:29, Average loss:152.1496\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:30, Average loss:157.0417\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:31, Average loss:154.4329\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:32, Average loss:156.1267\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:33, Average loss:155.0427\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:34, Average loss:154.5735\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:35, Average loss:150.2332\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:36, Average loss:157.1136\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:37, Average loss:155.8875\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:38, Average loss:145.9323\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:39, Average loss:151.5925\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "64\n",
      "epoch:40, Average loss:141.092\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-1f6441251b06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;31m#Step through each node and conduct a random walk about it of length max_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomWalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweb_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdomain_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-478808181607>\u001b[0m in \u001b[0;36mrandomWalk\u001b[1;34m(graph, initial_node, step, max_step, path)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mnext_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madjacent_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\euix\\anaconda3\\envs\\tensorflow-gpu\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mpool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# move non-selected item into vacancy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mselected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_loss_record = []\n",
    "list_batch_labels = []\n",
    "list_batch_inputs = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    print('Initialized')\n",
    "\n",
    "    average_loss = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        #Shuffle the list of nodes at the start of each epoch\n",
    "        random.shuffle(list_of_nodes)\n",
    "        random_walks = []\n",
    "        \n",
    "        for node in nodes_only:\n",
    "            #Step through each node and conduct a random walk about it of length max_step\n",
    "            path = randomWalk(web_graph, node, 0, max_step, [node])\n",
    "            \n",
    "            path = [domain_map[i] for i in path]\n",
    "            random_walks.append(path)\n",
    "        \n",
    "        data_windows = np.array(random_walks)\n",
    "                \n",
    "        target = data_windows[:,window_size]\n",
    "\n",
    "        left_window = data_windows[:,:window_size]\n",
    "\n",
    "        right_window = data_windows[:,window_size+1:]\n",
    "\n",
    "        context_window = np.concatenate([left_window, right_window], axis=1)\n",
    "            \n",
    "        for step in range(num_steps):\n",
    "\n",
    "            batch_data = generateBatch(batch_size, num_skips, context_window, target, step)\n",
    "            batch_inputs = [row[0] for row in batch_data]\n",
    "            batch_labels = [row[1] for row in batch_data]\n",
    "           \n",
    "            feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "            list_batch_labels.append([batch_labels])\n",
    "            list_batch_inputs.append([batch_inputs])\n",
    "            \n",
    "            _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "            \n",
    "            average_loss += loss_val\n",
    "         \n",
    "        if epoch%1==0: \n",
    "            \n",
    "            avg_loss_record.append(float(average_loss)/num_steps)\n",
    "            print('epoch:%d, Average loss:%.7g' % (epoch, float(average_loss)/num_steps))\n",
    "        \n",
    "        average_loss = 0\n",
    "\n",
    "        final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1114, 7453,   -1],\n",
       "       [1115,  114, 1069],\n",
       "       [5538, 1750,  706],\n",
       "       ..., \n",
       "       [7816, 3916, 3556],\n",
       "       [4409, 8508, 5035],\n",
       "       [3287, 4147,   -1]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCYAAAF3CAYAAAB5QUrKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC60AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27bb17fbb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_loss = np.array(avg_loss_record)\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot([i for \n",
    "          i in range(len(list_loss))], list_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#Create cosine similarity matrix\n",
    "\n",
    "mult_vector = tf.matmul(vector, vector, transpose_b=True)\n",
    "sim_matrix = tf.acos(mult_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    matrices = sess.run([sim_matrix, mult_vector] , feed_dict={vector:final_embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = matrices[0]\n",
    "\n",
    "np.fill_diagonal(sim_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in web_graph.neighbors('sellercentral.amazon.ca')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(web_graph, open('graph_directed.pkl', 'wb'))\n",
    "pickle.dump(final_embeddings, open('embeddings_test_domain_graph_directed.pkl', 'wb'))\n",
    "pickle.dump(sim_matrix, open('cosine_matrix_test_domain_graph_directed.pkl', 'wb'))\n",
    "pickle.dump(domain_inv_map, open('domain_inv_map_directed.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
